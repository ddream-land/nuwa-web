"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.OpenAIEmbeddings = void 0;
const axios_1 = __importDefault(require("axios"));
/**
 * A `PromptCompletionModel` for calling OpenAI and Azure OpenAI hosted models.
 * @remarks
 */
class OpenAIEmbeddings {
    /**
     * Creates a new `OpenAIClient` instance.
     * @param options Options for configuring an `OpenAIClient`.
     */
    constructor(options) {
        this.UserAgent = 'AlphaWave';
        this.maxTokens = 8000;
        // Check for azure config
        if (options.azureApiKey) {
            this._useAzure = true;
            this.options = Object.assign({
                retryPolicy: [2000, 5000],
                azureApiVersion: '2023-05-15',
            }, options);
            // Cleanup and validate endpoint
            let endpoint = this.options.azureEndpoint.trim();
            if (endpoint.endsWith('/')) {
                endpoint = endpoint.substring(0, endpoint.length - 1);
            }
            if (!endpoint.toLowerCase().startsWith('https://')) {
                throw new Error(`Client created with an invalid endpoint of '${endpoint}'. The endpoint must be a valid HTTPS url.`);
            }
            this.options.azureEndpoint = endpoint;
        }
        else {
            this._useAzure = false;
            this.options = Object.assign({
                retryPolicy: [2000, 5000]
            }, options);
        }
        // Create client
        this._httpClient = axios_1.default.create({
            validateStatus: (status) => true
        });
    }
    /**
     * Creates embeddings for the given inputs using the OpenAI API.
     * @param model Name of the model to use (or deployment for Azure).
     * @param inputs Text inputs to create embeddings for.
     * @returns A `EmbeddingsResponse` with a status and the generated embeddings or a message when an error occurs.
     */
    createEmbeddings(inputs) {
        return __awaiter(this, void 0, void 0, function* () {
            const response = yield this.createEmbeddingRequest({
                input: inputs,
            });
            // Process response
            if (response.status < 300) {
                return { status: 'success', output: response.data.data.sort((a, b) => a.index - b.index).map((item) => item.embedding) };
            }
            else if (response.status == 429) {
                return { status: 'rate_limited', message: `The embeddings API returned a rate limit error.` };
            }
            else {
                return { status: 'error', message: `The embeddings API returned an error status of ${response.status}: ${response.statusText}` };
            }
        });
    }
    /**
     * @private
     */
    createEmbeddingRequest(request) {
        var _a;
        if (this._useAzure) {
            const options = this.options;
            const url = `${options.azureEndpoint}/openai/deployments/${options.azureDeployment}/embeddings?api-version=${options.azureApiVersion}`;
            return this.post(url, request);
        }
        else {
            const options = this.options;
            const url = `${(_a = options.endpoint) !== null && _a !== void 0 ? _a : 'https://api.openai.com'}/v1/embeddings`;
            request.model = options.model;
            return this.post(url, request);
        }
    }
    /**
     * @private
     */
    post(url, body, retryCount = 0) {
        return __awaiter(this, void 0, void 0, function* () {
            // Initialize request config
            const requestConfig = Object.assign({}, this.options.requestConfig);
            // Initialize request headers
            if (!requestConfig.headers) {
                requestConfig.headers = {};
            }
            if (!requestConfig.headers['Content-Type']) {
                requestConfig.headers['Content-Type'] = 'application/json';
            }
            if (!requestConfig.headers['User-Agent']) {
                requestConfig.headers['User-Agent'] = this.UserAgent;
            }
            if (this._useAzure) {
                const options = this.options;
                requestConfig.headers['api-key'] = options.azureApiKey;
            }
            else {
                const options = this.options;
                requestConfig.headers['Authorization'] = `Bearer ${options.apiKey}`;
                if (options.organization) {
                    requestConfig.headers['OpenAI-Organization'] = options.organization;
                }
            }
            // Send request
            const response = yield this._httpClient.post(url, body, requestConfig);
            // Check for rate limit error
            if (response.status == 429 && Array.isArray(this.options.retryPolicy) && retryCount < this.options.retryPolicy.length) {
                const delay = this.options.retryPolicy[retryCount];
                yield new Promise((resolve) => setTimeout(resolve, delay));
                return this.post(url, body, retryCount + 1);
            }
            else {
                return response;
            }
        });
    }
}
exports.OpenAIEmbeddings = OpenAIEmbeddings;
//# sourceMappingURL=OpenAIEmbeddings.js.map